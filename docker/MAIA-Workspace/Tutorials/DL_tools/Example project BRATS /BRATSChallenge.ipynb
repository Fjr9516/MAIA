{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Segmentation Challenge\n",
    "The BRATSChallenge is a yearly competition for brain tumor segmentation organised by the Medical Image Computing Society of North America (MICCAI).\n",
    "\n",
    "The dataset consists of brain MRI scans of patients with gliomas, which are the most common type of primary brain tumor. The dataset is quite large so it will take a while to download. We will download the training data in the code below for you and load it in utils/brats_dataset.py. We have simplified the challenge to only consider 2D slices from the MRI scans and only segment the tumor and not classify into different types of tumors. You may of course try to classify into different types of tumors if you wish, after you have tuned your model for the binary segmentation task.\n",
    "\n",
    "\n",
    "The dataset is split into training and testing sets, with the testing set being used for the final evaluation of the submitted segmentation algorithms. We will simplify the challenge and only consider 2D slices from the MRI scans.\n",
    "\n",
    "The goal of this tutorial is to train and tune a model for the BRATSChallenge. We will provide you with an example training script, which you will need to modify and tune for the challenge or implement your own. It is often not necessary to run 10 epochs to know if a model is working or not and don't wait until the training is completely done to check if it is working. This may waste a lot of time. Debug by training on a single batch, tune hyperparameters on the validation set with shorter training time and then train for longer. Also check that each part of your pipeline is working, if you add augmentations, check that they are working by plotting the images and masks.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Explore the dataset and the example training script.\n",
    "2. Consider how you may improve the model's performance.\n",
    "3. Explore: data augmentation, image size, model architecture, loss function, optimizer, learning rate, etc.\n",
    "4. Evaluate the performance of your model with metrics appropriate for the task. Look at MONAI documentation for metrics.\n",
    "5. Submit your code and a short report/description of your approach. \n",
    "\n",
    "We encourage you to use a good training practice for this lab. This means that you should:\n",
    "\n",
    "1. Use a validation set to tune your model.\n",
    "2. Use a loss function and optimizer that are appropriate for the task.\n",
    "3. Use a learning rate that is appropriate for the task.\n",
    "4. Use a batch size that is appropriate for the task and the size of your GPU.\n",
    "5. Use data augmentation techniques that are appropriate for the task.\n",
    "6. Implement regularization if necessary to prevent overfitting if needed.\n",
    "7. Not load the entire dataset into memory.\n",
    "8. Save your model and checkpoints.\n",
    "9. Optional: Monitor and log training progress using tools like TensorBoard.\n",
    "10. Evaluate the performance of your model with metrics appropriate for the task at least: Dice coefficient, precision, recall, AUC\n",
    "\n",
    "\n",
    "We have provided you with a basic model implementation and structure on how to load the data and train the model. You will need to modify the code to improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lab example has a requirement for tensorboard, which you can install by running the command below in the terminal\n",
    "#conda activate DL_labs_GPU && pip install -U tensorboard\n",
    "\n",
    "# In your own code you choose whether to use Tensorboard or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.brats_dataset import get_brats_dataloader\n",
    "from utils.model import get_unet_model\n",
    "from utils.train import train\n",
    "from utils.evaluation import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"datasets\"  # Update this to your dataset directory\n",
    "batch_size = 8\n",
    "num_workers = 4  \n",
    "\n",
    "epochs = 3\n",
    "save_dir = \"utils/checkpoints\"\n",
    "log_path = \"utils/logs\"\n",
    "load_path = None  # Set to a checkpoint path if you want to resume training\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train_dataloader = get_brats_dataloader(root_dir, \"training\", batch_size, num_workers, shuffle=True)\n",
    "print(\"Loading validation data...\")\n",
    "val_dataloader = get_brats_dataloader(root_dir, \"validation\", batch_size, num_workers, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = get_unet_model(in_channels=4, out_channels=1)\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trained_model = train(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    save_dir=save_dir,\n",
    "    save_interval=2,\n",
    "    log_path=log_path,\n",
    "    load_path=load_path,\n",
    "    overfit_batch=False\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Starting evaluation on validation set...\")\n",
    "evaluate(trained_model, val_dataloader, device)\n",
    "print(\"Starting evaluation on training set...\")\n",
    "evaluate(trained_model, train_dataloader, device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_labs_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
