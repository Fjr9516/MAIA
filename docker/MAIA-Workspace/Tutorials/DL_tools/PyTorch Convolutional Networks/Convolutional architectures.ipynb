{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Architectures Lab\n",
    "\n",
    "This lab explores three influential convolutional neural network (CNN) architectures:\n",
    "\n",
    "1. [AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf): A deep CNN that significantly improved image classification performance.\n",
    "2. [VGG](https://arxiv.org/abs/1409.1556): Known for its simplicity and depth, using small, uniform convolutional filters.\n",
    "3. [ResNet](https://arxiv.org/abs/1512.03385): Introduced residual connections, allowing for much deeper networks and addressing the vanishing gradient problem.\n",
    "\n",
    "You will implement these architectures and apply them to the OrgansMNIST dataset from the MedMNIST collection. This hands-on experience will help you understand the design principles and performance characteristics of each architecture.\n",
    "\n",
    "The lab begins with data loading and preprocessing, as shown in the code above. You'll then proceed to implement and train each model, comparing their performance on the pneumonia classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5719),(0.1684)) \n",
    "            ])\n",
    "\n",
    "# load medMNIST datset\n",
    "\n",
    "from medmnist import OrganSMNIST\n",
    "dataset_train = OrganSMNIST(root='utils/datasets', split='train', transform=transform, download=True)\n",
    "loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "dataset_val = OrganSMNIST(root='utils/datasets', split='val', transform=transform, download=True)\n",
    "loader_val = DataLoader(dataset_val, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "dataset_test = OrganSMNIST(root='utils/datasets', split='test', transform=transform, download=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=64, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first image in the training set\n",
    "image, label = dataset_train[5]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Implementation\n",
    "\n",
    "AlexNet, introduced in 2012, was a groundbreaking convolutional neural network architecture that significantly improved image classification performance. It consists of 5 convolutional layers followed by 3 fully connected layers. Key features include:\n",
    "\n",
    "1. ReLU activations for faster training\n",
    "2. Local Response Normalization (LRN) for improved generalization\n",
    "3. Overlapping max pooling to reduce overfitting\n",
    "4. Data augmentation and dropout for regularization\n",
    "\n",
    "Your task is to implement AlexNet using PyTorch, adapting it for the OrgansMNIST dataset. Note that you may need to modify the original architecture slightly to accommodate the different input size of the OrgansMNIST images (28x28) compared to ImageNet (224x224). Please follow the instructions in the utils/models/alexnet.py file and run the cell below to load and test the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.models.alexnet as alexnet\n",
    "import torch\n",
    "\n",
    "model = alexnet.AlexNet(num_classes=11, in_channels=1)\n",
    "\n",
    "def test_shape(model):\n",
    "    x = torch.randn(16, 1, 28, 28)\n",
    "    assert model(x).shape == (16, 11)\n",
    "    print(\"Test passed\")\n",
    "\n",
    "test_shape(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AlexNet\n",
    "\n",
    "Now that you have implemented the AlexNet architecture, follow these steps to set up the training process:\n",
    "\n",
    "1. Define the loss function and optimizer:\n",
    "   - Choose an appropriate loss function (e.g., CrossEntropyLoss)\n",
    "   - Select an optimizer (e.g., Adam) and set the learning rate\n",
    "\n",
    "2. Create a training loop:\n",
    "   - Iterate through a specified number of epochs\n",
    "   - For each batch in the training data:\n",
    "     - Move data to the appropriate device (CPU/GPU)\n",
    "     - Perform forward pass, calculate loss, and backpropagate\n",
    "     - Update model parameters\n",
    "   - Print training progress at regular intervals\n",
    "\n",
    "3. Implement a validation function:\n",
    "   - Create a function to evaluate the model's performance on a given dataset\n",
    "   - Calculate and return the accuracy\n",
    "\n",
    "4. Train the model and monitor performance:\n",
    "   - Run the training loop\n",
    "   - After each epoch, evaluate the model on the validation set\n",
    "   - Track and plot training loss and validation accuracy over time\n",
    "\n",
    "5. Test the model:\n",
    "   - Evaluate the trained model on the test set\n",
    "   - Report the final test accuracy\n",
    "\n",
    "Remember to move your model to the appropriate device (CPU or GPU) before training.\n",
    "\n",
    "Experiment with different hyperparameters such as learning rate, batch size, and number of epochs to improve the model's performance.\n",
    "\n",
    "Please fill in the remaining code in train.py and run the cell below to train the model. You should expect to see test accuracy > 75 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet.AlexNet(num_classes=11, in_channels=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "from utils.train import train, check_accuracy\n",
    "\n",
    "# Train the model\n",
    "model, results = train(model, loader_train, loader_val, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Check accuracy on the test set\n",
    "test_loss, test_accuracy = check_accuracy(model, loader_test, criterion, device)\n",
    "train_loss, train_accuracy = check_accuracy(model, loader_train, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract variables from results dictionary\n",
    "train_loss = results['train_loss']\n",
    "val_loss = results['val_loss']\n",
    "val_accuracy = results['val_accuracy']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Implementation\n",
    "\n",
    "VGG, introduced in 2014, is known for its simplicity and depth, using small, uniform convolutional filters. It consists of 16 or 19 convolutional layers followed by 3 fully connected layers. Key features include:\n",
    "\n",
    "1. Small, uniform convolutional filters (3x3)\n",
    "2. Max pooling for downsampling\n",
    "3. Dropout for regularization\n",
    "4. Data augmentation\n",
    "\n",
    "Follow the instructions in the utils/models/vgg.py file and run the cell below to load and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.models.vgg as vgg\n",
    "import torch\n",
    "\n",
    "model = vgg.VGG13(num_classes=11, in_channels=1)\n",
    "\n",
    "def test_shape(model):\n",
    "    x = torch.randn(16, 1, 28, 28)\n",
    "    assert model(x).shape == (16, 11)\n",
    "    print(\"Test passed\")\n",
    "\n",
    "test_shape(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg.VGG13(num_classes=11, in_channels=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "from utils.train import train, check_accuracy\n",
    "\n",
    "# Train the model\n",
    "model, results = train(model, loader_train, loader_val, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Check accuracy on the test set\n",
    "test_loss, test_accuracy = check_accuracy(model, loader_test, criterion, device)\n",
    "train_loss, train_accuracy = check_accuracy(model, loader_train, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "What is the difference between AlexNet and VGG in the training results? Can you explain these results in terms of the architectures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract variables from results dictionary\n",
    "train_loss = results['train_loss']\n",
    "val_loss = results['val_loss']\n",
    "val_accuracy = results['val_accuracy']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add regularization\n",
    "Re-run the training process of vgg with dropout and L2 regularization. For dropout you may need to modify the code in the utils/models/vgg.py file. Think carefully about where to add dropout in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code below with dropout and L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Implementation\n",
    "\n",
    "ResNet, introduced in 2015, introduced residual connections, allowing for much deeper networks and addressing the vanishing gradient problem. It consists of convolutional layers with residual connections. Key features include:\n",
    "\n",
    "1. Residual connections for faster training\n",
    "2. Batch normalization for faster training\n",
    "\n",
    "\n",
    "Follow the instructions in the utils/models/resnet.py file and run the cell below to load and test the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.models.resnet as resnet\n",
    "import torch\n",
    "\n",
    "model = resnet.ResNet50(num_classes=11, in_channels=1)\n",
    "\n",
    "def test_shape(model):\n",
    "    x = torch.randn(16, 1, 28, 28)\n",
    "    assert model(x).shape == (16, 11)\n",
    "    print(\"Test passed\")\n",
    "\n",
    "test_shape(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ResNet\n",
    "\n",
    "Now that you have implemented the ResNet architecture, follow these steps to set up the training process:\n",
    "\n",
    "1. Define the loss function and optimizer:\n",
    "   - Choose an appropriate loss function (e.g., CrossEntropyLoss)\n",
    "   - Select an optimizer (e.g., Adam) and set the learning rate\n",
    "\n",
    "2. Create a training loop:\n",
    "   - Iterate through a specified number of epochs\n",
    "\n",
    "You should expect to see test accuracy > 74 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code below\n",
    "model = resnet.ResNet50(num_classes=11, in_channels=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Import necessary functions from utils.train\n",
    "from utils.train import train, check_accuracy\n",
    "\n",
    "# Train the model\n",
    "model, results = train(model, loader_train, loader_val, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Check accuracy on the test set\n",
    "test_loss, test_accuracy = check_accuracy(model, loader_test, criterion, device)\n",
    "train_loss, train_accuracy = check_accuracy(model, loader_train, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results loss plots and accuracy plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "What are some possible issues with the training process of the ResNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
